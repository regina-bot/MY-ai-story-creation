import streamlit as st
import google.generativeai as genai
import sqlite3
import json
import time
from datetime import datetime
from streamlit_agraph import agraph, Node, Edge, Config


# --- 1. æ•°æ®åº“é€»è¾‘ (ç»Ÿä¸€è·¯å¾„ï¼Œé€‚é…äº‘ç«¯) ---
def init_db():
    # åˆ æ‰äº† ../ ç¡®ä¿åœ¨äº‘ç«¯ä¹Ÿèƒ½æ­£å¸¸åˆ›å»ºæ•°æ®åº“
    conn = sqlite3.connect('story_station_pro.db', check_same_thread=False)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS analysis_history
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  filename TEXT,
                  summary TEXT,
                  time TEXT)''')
    conn.commit()
    return conn


# --- 2. å…³ç³»å›¾æ¸²æŸ“é€»è¾‘ (ä¿æŒä¸å˜) ---
def render_graph(raw_text):
    try:
        start = raw_text.find('{')
        end = raw_text.rfind('}') + 1
        if start == -1 or end == 0:
            return st.info("è¯¥æ¡è®°å½•æœªåŒ…å«å¯è¯†åˆ«çš„äººç‰©å…³ç³»æ•°æ®ã€‚")

        data = json.loads(raw_text[start:end])
        nodes = [Node(id=name, label=name, size=20, color="#FF4B4B") for name in data.get('nodes', [])]
        edges = [Edge(source=e[0], target=e[1], label=e[2]) for e in data.get('edges', [])]

        config = Config(width=800, height=500, directed=True, nodeHighlightBehavior=True)
        return agraph(nodes=nodes, edges=edges, config=config)
    except Exception:
        st.warning("æš‚æ— æ³•ç”Ÿæˆå…³ç³»å›¾è°±ï¼Œå¯èƒ½ JSON æ ¼å¼ä¸è§„èŒƒã€‚")


# --- 3. é¡µé¢é…ç½®ä¸åˆå§‹åŒ– ---
st.set_page_config(layout="wide", page_title="AI æ–‡å­¦æ·±åº¦åˆ†æç«™", page_icon="ğŸ“‘")
conn = init_db()

# ä¾§è¾¹æ ï¼šå†å²æ¡£æ¡ˆç®¡ç†
with st.sidebar:
    st.title("ğŸ“š å†å²åˆ†ææ¡£æ¡ˆ")
    st.write("---")
    cursor = conn.cursor()
    history = cursor.execute("SELECT id, filename, time FROM analysis_history ORDER BY id DESC").fetchall()

    for item in history:
        col_name, col_del = st.columns([4, 1])
        with col_name:
            if st.button(f"ğŸ“„ {item[1]}\n({item[2]})", key=f"hist_{item[0]}"):
                st.session_state.selected_id = item[0]

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è®°å½•"):
        conn.execute("DELETE FROM analysis_history")
        conn.commit()
        st.rerun()

# --- 4. ä¸»ç•Œé¢ï¼šé€»è¾‘ç»“æ„ä¼˜åŒ– ---
st.title("ğŸ§  æ·±åº¦æ•…äº‹åˆ†æå·¥ä½œç«™")
st.markdown("æ”¯æŒå¤šæ–‡ä»¶å¤„ç†ã€æµå¼å®æ—¶è¾“å‡ºåŠäººç‰©å…³ç³»å»ºæ¨¡")

# --- ä¼˜åŒ–åçš„ API Key å¤„ç†é€»è¾‘ ---
api_key = ""
# 1. ä¼˜å…ˆå°è¯•ä» Secretsï¼ˆäº‘ç«¯/æœ¬åœ°é…ç½®ï¼‰è¯»å–
if "GEMINI_API_KEY" in st.secrets and st.secrets["GEMINI_API_KEY"]:
    api_key = st.secrets["GEMINI_API_KEY"]
    st.sidebar.success("ğŸ”‘ API Key å·²å®‰å…¨åŠ è½½")
else:
    # 2. å¦‚æœæ²¡é…ï¼Œæ‰åœ¨ä¸»é¡µæ˜¾ç¤ºè¾“å…¥æ¡†
    api_key = st.text_input("Gemini API Key", type="password", help="è¯·åœ¨åå°é…ç½®ä»¥éšè—æ­¤æ¡†")

# --- ç»Ÿä¸€çš„æ–‡ä»¶ä¸Šä¼ åŒº (åªå†™ä¸€æ¬¡) ---
uploaded_files = st.file_uploader("ğŸ“‚ ä¸Šä¼  TXT æ–‡ä»¶ (æ”¯æŒæ‰¹é‡)", type="txt", accept_multiple_files=True)

if uploaded_files and st.button("ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ"):
    if not api_key:
        st.error("è¯·è¾“å…¥ API Key åå†ç»§ç»­ã€‚")
    else:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')

        for index, file in enumerate(uploaded_files):
            if file.size > 1024 * 1024:
                st.warning(f"è·³è¿‡ {file.name}: æ–‡ä»¶è¶…è¿‡ 1MB é™åˆ¶ã€‚")
                continue

            try:
                # ç¡®ä¿æ¯æ¬¡å¾ªç¯éƒ½è¯»å–æ–‡ä»¶å†…å®¹
                content = file.read().decode("utf-8", errors="ignore")

                prompt = f"""
                ä½œä¸ºæ–‡å­¦åˆ†æä¸“å®¶ï¼Œè¯·é˜…è¯»ä¸‹æ–‡å¹¶è¾“å‡ºï¼š
                1. æ–‡ç« å¤§æ„æ€»ç»“ã€‚
                2. æ•…äº‹ä¸»è¦æƒ…èŠ‚ã€‚
                3. äººç‰©å…³ç³» JSON (å¿…é¡»ä¸¥æ ¼æ”¾åœ¨å›ç­”æœ€å)ã€‚
                æ ¼å¼æ¨¡æ¿ï¼š
                {{ "nodes": ["è§’è‰²A"], "edges": [["è§’è‰²A", "è§’è‰²B", "å…³ç³»"]] }}
                å†…å®¹ï¼š{content}
                """

                st.subheader(f"æ­£åœ¨åˆ†æ: {file.name}")

                # æµå¼ç”Ÿæˆ
                response = model.generate_content(prompt, stream=True)


                def stream_data():
                    full_res = ""
                    for chunk in response:
                        full_res += chunk.text
                        yield chunk.text

                    # åªæœ‰æµç»“æŸåæ‰å†™å…¥æ•°æ®åº“
                    now = datetime.now().strftime("%m-%d %H:%M")
                    # ä½¿ç”¨å½“å‰çº¿ç¨‹çš„è¿æ¥
                    temp_conn = sqlite3.connect('story_station_pro.db')
                    temp_conn.execute("INSERT INTO analysis_history (filename, summary, time) VALUES (?, ?, ?)",
                                      (file.name, full_res, now))
                    temp_conn.commit()
                    temp_conn.close()


                st.write_stream(stream_data)
                st.success(f"{file.name} åˆ†æå®Œæ¯•ï¼")

                if index < len(uploaded_files) - 1:
                    time.sleep(5)  # ç¨å¾®ç¼©çŸ­ç­‰å¾…æ—¶é—´

            except Exception as e:
                st.error(f"åˆ†æ {file.name} æ—¶å‡ºé”™: {e}")

# --- 5. ç»“æœå±•ç¤ºåŒº ---
if 'selected_id' in st.session_state:
    res = conn.execute("SELECT filename, summary FROM analysis_history WHERE id=?",
                       (st.session_state.selected_id,)).fetchone()

    if res:
        st.divider()
    st.header(f"ğŸ“‘ æŠ¥å‘Šè¯¦æƒ…ï¼š{res[0]}")
    tab1, tab2 = st.tabs(["ğŸ“– é˜…è¯»æ€»ç»“", "ğŸ•¸ï¸ äººç‰©å…³ç³»å›¾è°±"])
    with tab1:
        st.markdown(res[1].split('{')[0])
    with tab2:
        render_graph(res[1])