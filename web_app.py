import streamlit as st
import google.generativeai as genai
import sqlite3
import json
import time
from datetime import datetime
from streamlit_agraph import agraph, Node, Edge, Config


# --- 1. æ•°æ®åº“é€»è¾‘ (æŒä¹…åŒ–å­˜å‚¨å†å²è®°å½•) ---
def init_db():
    conn = sqlite3.connect('../story_station_pro.db', check_same_thread=False)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS analysis_history
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  filename TEXT,
                  summary TEXT,
                  time TEXT)''')
    conn.commit()
    return conn


# --- 2. å…³ç³»å›¾æ¸²æŸ“é€»è¾‘ ---
def render_graph(raw_text):
    try:
        # ä»æ··åˆæ–‡æœ¬ä¸­æå–æœ€åçš„ JSON å—
        start = raw_text.find('{')
        end = raw_text.rfind('}') + 1
        if start == -1 or end == 0:
            return st.info("è¯¥æ¡è®°å½•æœªåŒ…å«å¯è¯†åˆ«çš„äººç‰©å…³ç³»æ•°æ®ã€‚")

        data = json.loads(raw_text[start:end])
        nodes = [Node(id=name, label=name, size=20, color="#FF4B4B") for name in data.get('nodes', [])]
        edges = [Edge(source=e[0], target=e[1], label=e[2]) for e in data.get('edges', [])]

        config = Config(width=800, height=500, directed=True, nodeHighlightBehavior=True)
        return agraph(nodes=nodes, edges=edges, config=config)
    except Exception:
        st.warning("æš‚æ— æ³•ç”Ÿæˆå…³ç³»å›¾è°±ï¼Œå¯èƒ½ JSON æ ¼å¼ä¸è§„èŒƒã€‚")


# --- 3. é¡µé¢é…ç½®ä¸åˆå§‹åŒ– ---
st.set_page_config(layout="wide", page_title="AI æ–‡å­¦æ·±åº¦åˆ†æç«™", page_icon="ğŸ“‘")
conn = init_db()

# ä¾§è¾¹æ ï¼šå†å²æ¡£æ¡ˆç®¡ç†
with st.sidebar:
    st.title("ğŸ“š å†å²åˆ†ææ¡£æ¡ˆ")
    st.write("---")
    cursor = conn.cursor()
    history = cursor.execute("SELECT id, filename, time FROM analysis_history ORDER BY id DESC").fetchall()

    for item in history:
        col_name, col_del = st.columns([4, 1])
        with col_name:
            if st.button(f"ğŸ“„ {item[1]}\n({item[2]})", key=f"hist_{item[0]}"):
                st.session_state.selected_id = item[0]

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è®°å½•"):
        conn.execute("DELETE FROM analysis_history")
        conn.commit()
        st.rerun()

# --- 4. ä¸»ç•Œé¢ï¼šæ–‡ä»¶å¤„ç†ä¸æµå¼åˆ†æ ---
st.title("ğŸ§  æ·±åº¦æ•…äº‹åˆ†æå·¥ä½œç«™")
st.markdown("æ”¯æŒå¤šæ–‡ä»¶å¤„ç†ã€æµå¼å®æ—¶è¾“å‡ºåŠäººç‰©å…³ç³»å»ºæ¨¡")

# å°è¯•ä» secrets è·å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è®¾ä¸º None
try:
    default_key = st.secrets["GEMINI_API_KEY"]
except:
    default_key = ""

col_api, col_file = st.columns([1, 2])
with col_api:
    # å¦‚æœ secrets é‡Œæœ‰å€¼ï¼Œè¿™é‡Œä¼šè‡ªåŠ¨å¡«å…¥
    api_key = st.text_input(
        "Gemini API Key",
        value=default_key,
        type="password",
        help="å·²è‡ªåŠ¨åŠ è½½æœ¬åœ°é…ç½®ï¼Œå¦‚éœ€æ›´æ¢è¯·åœ¨æ­¤ä¿®æ”¹"
    )
    uploaded_files = st.file_uploader("ä¸Šä¼  TXT æ–‡ä»¶ (æ”¯æŒæ‰¹é‡)", type="txt", accept_multiple_files=True)

if uploaded_files and st.button("ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ"):
    if not api_key:
        st.error("è¯·è¾“å…¥ API Key åå†ç»§ç»­ã€‚")
    else:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')

        for index, file in enumerate(uploaded_files):
            # A. æ–‡ä»¶å¤§å°é™åˆ¶ (1MB)
            if file.size > 1024 * 1024:
                st.warning(f"è·³è¿‡ {file.name}: æ–‡ä»¶è¶…è¿‡ 1MB é™åˆ¶ã€‚")
                continue

            try:
                content = file.read().decode("utf-8", errors="ignore")

                # B. æ„å»º Prompt
                prompt = f"""
                ä½œä¸ºæ–‡å­¦åˆ†æä¸“å®¶ï¼Œè¯·é˜…è¯»ä¸‹æ–‡å¹¶è¾“å‡ºï¼š
                1. æ–‡ç« å¤§æ„æ€»ç»“ã€‚
                2. æ•…äº‹ä¸»è¦æƒ…èŠ‚ã€‚
                3. äººç‰©å…³ç³» JSON (å¿…é¡»ä¸¥æ ¼æ”¾åœ¨å›ç­”æœ€å)ã€‚

                æ ¼å¼æ¨¡æ¿ï¼š
                {{ "nodes": ["è§’è‰²A"], "edges": [["è§’è‰²A", "è§’è‰²B", "å…³ç³»"]] }}

                å†…å®¹ï¼š{content}
                """

                st.subheader(f"æ­£åœ¨åˆ†æ: {file.name}")

                # C. æµå¼è¾“å‡ºæ•ˆæœ
                # ä½¿ç”¨ stream=True å¼€å¯æµå¼ä¼ è¾“
                response = model.generate_content(prompt, stream=True)


                def stream_data():
                    full_response = ""
                    for chunk in response:
                        full_response += chunk.text
                        yield chunk.text
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    now = datetime.now().strftime("%m-%d %H:%M")
                    conn.execute("INSERT INTO analysis_history (filename, summary, time) VALUES (?, ?, ?)",
                                 (file.name, full_response, now))
                    conn.commit()


                # åœ¨ç•Œé¢ä¸Šå±•ç¤ºæ‰“å­—æœºæ•ˆæœ
                st.write_stream(stream_data)
                st.success(f"{file.name} åˆ†æå¹¶ä¿å­˜æˆåŠŸï¼")
                # D. é¢‘ç‡é™åˆ¶ä¿æŠ¤ (å¤šæ–‡ä»¶æ—¶)
                if index < len(uploaded_files) - 1:
                    st.info("ç­‰å¾… API é…é¢åˆ·æ–° (10ç§’)...")
                    time.sleep(10)

            except Exception as e:
                st.error(f"åˆ†æ {file.name} æ—¶å‡ºé”™: {e}")
# --- 5. ç»“æœå±•ç¤ºåŒº (æŸ¥çœ‹å†å²æˆ–åˆšç”Ÿæˆçš„è®°å½•) ---
if 'selected_id' in st.session_state:
    res = conn.execute("SELECT filename, summary FROM analysis_history WHERE id=?",
                       (st.session_state.selected_id,)).fetchone()
    if res:
        st.divider()
        st.header(f"ğŸ“‘ æŠ¥å‘Šè¯¦æƒ…ï¼š{res[0]}")

        tab1, tab2 = st.tabs(["ğŸ“– é˜…è¯»æ€»ç»“", "ğŸ•¸ï¸ äººç‰©å…³ç³»å›¾è°±"])

        with tab1:
            # è¿‡æ»¤æ‰ JSONï¼Œåªæ˜¾ç¤ºæ–‡å­—
            text_only = res[1].split('{')[0]
            st.markdown(text_only)

        with tab2:
            st.info("ğŸ’¡ æç¤ºï¼šä½ å¯ä»¥ç”¨é¼ æ ‡æ‹–åŠ¨èŠ‚ç‚¹ï¼Œæˆ–ä½¿ç”¨æ»šè½®ç¼©æ”¾å›¾è°±ã€‚")
            render_graph(res[1])